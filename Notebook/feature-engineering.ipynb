{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# type: ignore\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_data(dataset):\n",
    "    df = pd.read_csv(f'../Data/raw/{dataset}-data.csv')\n",
    "    return df\n",
    "\n",
    "train_data = read_data('train')\n",
    "val_data = read_data('validation')\n",
    "test_data = read_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create a new features.\n",
    "def add_features(data):\n",
    "\n",
    "    # credit_scores\n",
    "    credit_bins = [299, 579, 669, 739, 799, 850]\n",
    "    credit_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "    data['credit_score_label'] = pd.cut(data['credit_score'], bins=credit_bins, labels=credit_labels)\n",
    "    # Age\n",
    "    age_bins = [17, 30, 40, 55, 70, 100]\n",
    "    age_labels = ['18-30', '31-40', '41-55', '56-70', '>70']\n",
    "    data['age_label'] = pd.cut(data.age, bins=age_bins, labels=age_labels)\n",
    "    data['age_young'] = (data.age < 35).astype('int')\n",
    "    data['age_old'] = (data.age > 60).astype('int')\n",
    "\n",
    "    # Age proportion based on train data\n",
    "    age_proportion_dict = (round(train_data['age_label'].value_counts(normalize=True) * 100)).to_dict()\n",
    "    data['age_label_proportion'] = data.age_label.map(age_proportion_dict).astype('int')\n",
    "\n",
    "    # Average Credit score by age groups\n",
    "    avg_credit_score = train_data.groupby(by=['age_label'], observed=False)['credit_score'].mean().to_dict()\n",
    "    data['avg_credit_score_by_age'] = data.age_label.map(avg_credit_score)\n",
    "\n",
    "    # Balance\n",
    "    data['zero_balance'] = (data.balance == 0).astype('int')\n",
    "    \n",
    "    # Tenure \n",
    "    data['new_customer'] = (data.tenure == 0).astype('int')\n",
    "    data['old_customer'] = (data.tenure > 8).astype('int')\n",
    "\n",
    "    # Number of products\n",
    "    data['single_product'] = (data.num_of_products == 1).astype('int')\n",
    "    data['mt3_product'] = (data.num_of_products > 3).astype('int')\n",
    "\n",
    "    # Gender\n",
    "    data['is_female'] = (data.gender.str.lower() == 'female').astype(int)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features(train_data)\n",
    "add_features(val_data)\n",
    "add_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'surname', 'credit_score', 'geography', 'gender', 'age',\n",
       "       'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
       "       'is_active_member', 'salary', 'churn', 'credit_score_label',\n",
       "       'age_label', 'age_young', 'age_old', 'age_label_proportion',\n",
       "       'avg_credit_score_by_age', 'zero_balance', 'new_customer',\n",
       "       'old_customer', 'single_product', 'mt3_product', 'is_female'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "num_features = ['credit_score', 'age', 'tenure', 'num_of_products', 'balance',\n",
    "                 'salary', 'age_label_proportion', 'avg_credit_score_by_age']\n",
    "cat_features = ['geography', 'credit_score_label', 'age_label']\n",
    "\n",
    "new_features = ['has_cr_card', 'is_active_member', 'age_young', 'age_old',\n",
    "                'zero_balance', 'new_customer', 'old_customer', 'single_product',\n",
    "                'mt3_product', 'is_female']\n",
    "\n",
    "features = num_features + cat_features + new_features\n",
    "\n",
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform numeric and categorical features\n",
    "def scale_data(scaler, data, num_features):\n",
    "\n",
    "    # Get the feature names\n",
    "    features = scaler.get_feature_names_out()\n",
    "    features = map(str.lower, features)\n",
    "    scaled_data = scaler.transform(data[num_features])\n",
    "    \n",
    "    # Create dataframe\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=features)\n",
    "    return scaled_df\n",
    "\n",
    "def encode_data(encoder, data, cat_features):\n",
    "\n",
    "    # Get the feature names\n",
    "    features = encoder.get_feature_names_out()\n",
    "    features = map(str.lower, features)\n",
    "    encoded_data = encoder.transform(data[cat_features])\n",
    "\n",
    "    # Create dataframe\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=features, dtype=int)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialized scaler \n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train[num_features])\n",
    "\n",
    "# Initalized one-hot encoder\n",
    "oh_en = OneHotEncoder(sparse_output=False)\n",
    "oh_en = oh_en.fit(X_train[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    scaled_data = scale_data(scaler, data, num_features)\n",
    "    oh_en_data  = encode_data(oh_en, data, cat_features)\n",
    "\n",
    "    data_transform = pd.concat([scaled_data, oh_en_data, data[new_features]], axis=1)\n",
    "    return data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data\n",
    "X_train_transform = transform_data(X_train)\n",
    "\n",
    "# Validation data\n",
    "X_val = val_data[features]\n",
    "y_val = val_data[target]\n",
    "X_val_transform = transform_data(X_val)\n",
    "\n",
    "# Test data\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]\n",
    "X_test_transform = transform_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 31), (2000, 31), (2000, 31))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of new transformed dataset\n",
    "X_train_transform.shape, X_val_transform.shape, X_test_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "def save_tocsv(data, filename):\n",
    "    data.to_csv(f'../Data/process/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformed datasets\n",
    "save_tocsv(X_train_transform, 'X_train_transformed')\n",
    "save_tocsv(X_val_transform, 'X_validation_transformed')\n",
    "save_tocsv(X_test_transform, 'X_test_transformed')\n",
    "\n",
    "# Save target datasets\n",
    "save_tocsv(y_train, 'y_train')\n",
    "save_tocsv(y_val, 'y_validation')\n",
    "save_tocsv(y_test, 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler and encoder model\n",
    "import pickle\n",
    "with open('../Model/transformer.pkl', 'wb+') as f:\n",
    "    pickle.dump((scaler, oh_en), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
