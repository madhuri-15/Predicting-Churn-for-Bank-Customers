{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# type: ignore\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_data(dataset):\n",
    "    df = pd.read_csv(f'../Data/raw/{dataset}-data.csv')\n",
    "    return df\n",
    "\n",
    "train_data = read_data('train')\n",
    "valid_data = read_data('validation')\n",
    "test_data = read_data('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feauture Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create a new features.\n",
    "def add_features(data):\n",
    "\n",
    "    # credit_scores\n",
    "    credit_bins = [299, 579, 669, 739, 799, 850]\n",
    "    credit_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "    data['credit_score_label'] = pd.cut(data['credit_score'], bins=credit_bins, labels=credit_labels)\n",
    "    # Age\n",
    "    age_bins = [17, 30, 40, 55, 70, 100]\n",
    "    age_labels = ['18-30', '31-40', '41-55', '56-70', '>70']\n",
    "    data['age_label'] = pd.cut(data.age, bins=age_bins, labels=age_labels)\n",
    "    data['age_young'] = (data.age < 35).astype('int')\n",
    "    data['age_old'] = (data.age > 60).astype('int')\n",
    "\n",
    "    # Age proportion based on train data\n",
    "    age_proportion_dict = (round(train_data['age_label'].value_counts(normalize=True) * 100)).to_dict()\n",
    "    data['age_label_proportion'] = data.age_label.map(age_proportion_dict).astype('int')\n",
    "\n",
    "    # Average Credit score by age groups\n",
    "    avg_credit_score = train_data.groupby(by=['age_label'], observed=False)['credit_score'].mean().to_dict()\n",
    "    data['avg_credit_score_by_age'] = data.age_label.map(avg_credit_score)\n",
    "\n",
    "    # Balance\n",
    "    data['zero_balance'] = (data.balance == 0).astype('int')\n",
    "    \n",
    "    # Tenure \n",
    "    data['new_customer'] = (data.tenure == 0).astype('int')\n",
    "    data['old_customer'] = (data.tenure > 8).astype('int')\n",
    "\n",
    "    # Number of products\n",
    "    data['single_product'] = (data.num_of_products == 1).astype('int')\n",
    "    data['mt3_product'] = (data.num_of_products > 3).astype('int')\n",
    "\n",
    "    # Gender\n",
    "    data['is_female'] = (data.gender.str.lower() == 'female').astype(int)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features(train_data)\n",
    "add_features(valid_data)\n",
    "add_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "num_features = ['credit_score', 'age', 'tenure', 'num_of_products', 'balance',\n",
    "                 'salary', 'age_label_proportion', 'avg_credit_score_by_age']\n",
    "cat_features = ['geography', 'credit_score_label', 'age_label']\n",
    "\n",
    "new_features = ['has_cr_card', 'is_active_member', 'age_young', 'age_old',\n",
    "                'zero_balance', 'new_customer', 'old_customer', 'single_product',\n",
    "                'mt3_product', 'is_female']\n",
    "\n",
    "features = num_features + cat_features + new_features\n",
    "\n",
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformation to features\n",
    "def get_scaled_data(scaler, data, num_features):\n",
    "    # Apply scaling transformation\n",
    "    scaled_data = scaler.transform(data[num_features])\n",
    "    # Save result in dataframe\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=num_features)\n",
    "    return scaled_df\n",
    "\n",
    "def get_encoded_data(encoder, data, cat_featues):\n",
    "    # Get the feature names\n",
    "    features = encoder.get_feature_names_out()\n",
    "    features = map(str.lower, features)\n",
    "    # Apply one-hot encoder\n",
    "    encoded_data = encoder.transform(data[cat_features])\n",
    "\n",
    "    # Create dataframe\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=features, dtype=int)\n",
    "    return encoded_df\n",
    "\n",
    "def transform(data):\n",
    "    # Apply transformation to data\n",
    "    scaled_df = get_scaled_data(scaler, data, num_features)\n",
    "    oh_en_df  = get_encoded_data(oh_en, data, cat_features)\n",
    "\n",
    "    # Combine transformed dataframes along with newly added features.\n",
    "    transform_data = pd.concat([scaled_df, oh_en_df, data[new_features], data[target]], axis=1)\n",
    "    return transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical feature transformation\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data[num_features])\n",
    "\n",
    "# For categorical feature transformation\n",
    "oh_en = OneHotEncoder(sparse_output=False)\n",
    "oh_en = oh_en.fit(train_data[cat_features])\n",
    "\n",
    "train_transform = transform(train_data)\n",
    "valid_transform = transform(valid_data)\n",
    "test_transform = transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "def save_to_csv(data, filename):\n",
    "    data.to_csv(f'../Data/process/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformed datasets\n",
    "save_to_csv(train_transform, 'train_transform')\n",
    "save_to_csv(valid_transform, 'valid_transform')\n",
    "save_to_csv(test_transform, 'test_transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler and encoder model\n",
    "import pickle\n",
    "with open('../Model/transformer.pkl', 'wb+') as f:\n",
    "    pickle.dump((scaler, oh_en), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
